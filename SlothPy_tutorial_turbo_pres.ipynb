{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e774ec7",
   "metadata": {},
   "source": [
    "Copyright (c) 2023, Mikołaj Tadeusz Żychowicz (MTZ). All rights reserved.\n",
    "\n",
    "SlothPy is released under the GNU General Public License v3 (GPLv3). For details, see the [LICENSE](https://github.com/MTZ-dev/slothpy/blob/main/LICENSE.txt) file.\n",
    "\n",
    "# SlothPy Tutorial\n",
    "<img src=\"https://raw.githubusercontent.com/MTZ-dev/slothpy/main/doc/source/_static/slothpy_3.png\" width=\"300\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d1597c3",
   "metadata": {},
   "source": [
    "I designed SlothPy to be used in interactive Jupyter notebooks and stand-alone scripts, which users can create and adjust to their needs, seemingly integrating into custom data pipelines. Remember, especially while working on Windows, to include into your programs `if __name__ == \"__main__\"` block for executing instructions after importing modules. You can follow the notebook or copy its contents to .py files and execute them as you prefer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac36f18",
   "metadata": {},
   "source": [
    "# HDF5 Integration in SlothPy\n",
    "\n",
    "SlothPy extensively utilizes the HDF5 file format—a versatile and portable binary format optimized for fast I/O operations and handling large datasets. The primary file extension used by SlothPy, `.slt`, is essentially an HDF5 file. This means it can be opened and manipulated with standard HDF5 tools like HDFView and HDFCompass or accessed programmatically via the `h5py` Python interface. Now, let's begin by importing SlothPy along with other essential packages for this tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41eba57d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'primme'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mslothpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mslt\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n",
      "File \u001b[0;32m~/Sloth/Sloth/slothpy/__init__.py:30\u001b[0m\n\u001b[1;32m     26\u001b[0m os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNUMBA_ENABLE_AVX\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmultiprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m current_process\n\u001b[0;32m---> 30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     31\u001b[0m     compound_from_orca,\n\u001b[1;32m     32\u001b[0m     compound_from_slt,\n\u001b[1;32m     33\u001b[0m     compound_from_molcas,\n\u001b[1;32m     34\u001b[0m     settings,\n\u001b[1;32m     35\u001b[0m     turn_on_monitor,\n\u001b[1;32m     36\u001b[0m     turn_off_monitor,\n\u001b[1;32m     37\u001b[0m     set_plain_error_reporting_mode,\n\u001b[1;32m     38\u001b[0m     set_default_error_reporting_mode,\n\u001b[1;32m     39\u001b[0m     set_double_precision,\n\u001b[1;32m     40\u001b[0m     set_single_precision,\n\u001b[1;32m     41\u001b[0m     set_log_level,\n\u001b[1;32m     42\u001b[0m )\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_general_utilities\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     44\u001b[0m     lebedev_laikov_grid,\n\u001b[1;32m     45\u001b[0m     color_map,\n\u001b[1;32m     46\u001b[0m )\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Compound\n",
      "File \u001b[0;32m~/Sloth/Sloth/slothpy/core/__init__.py:17\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# SlothPy\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Copyright (C) 2023 Mikolaj Tadeusz Zychowicz (MTZ)\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# You should have received a copy of the GNU General Public License\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# along with this program.  If not, see <https://www.gnu.org/licenses/>.\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcreation_functions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     18\u001b[0m     compound_from_molcas,\n\u001b[1;32m     19\u001b[0m     compound_from_orca,\n\u001b[1;32m     20\u001b[0m     compound_from_slt,\n\u001b[1;32m     21\u001b[0m )\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompound_object\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Compound\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_config\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     26\u001b[0m     settings,\n\u001b[1;32m     27\u001b[0m     turn_on_monitor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     33\u001b[0m     set_log_level,\n\u001b[1;32m     34\u001b[0m )\n",
      "File \u001b[0;32m~/Sloth/Sloth/slothpy/core/creation_functions.py:18\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# SlothPy\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Copyright (C) 2023 Mikolaj Tadeusz Zychowicz (MTZ)\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# You should have received a copy of the GNU General Public License\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# along with this program.  If not, see <https://www.gnu.org/licenses/>.\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpath\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m join\n\u001b[0;32m---> 18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mslothpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompound_object\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Compound\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mslothpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_general_utilities\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_io\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     20\u001b[0m     _orca_spin_orbit_to_slt,\n\u001b[1;32m     21\u001b[0m     _molcas_spin_orbit_to_slt,\n\u001b[1;32m     22\u001b[0m )\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mslothpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_slothpy_exceptions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SltFileError, SltInputError\n",
      "File \u001b[0;32m~/Sloth/Sloth/slothpy/core/compound_object.py:121\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mslothpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_general_utilities\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_grids_over_sphere\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m    117\u001b[0m     _meshgrid_over_sphere_flatten,\n\u001b[1;32m    118\u001b[0m     _fibonacci_over_sphere,\n\u001b[1;32m    119\u001b[0m )\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mslothpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_input_parser\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m validate_input\n\u001b[0;32m--> 121\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mslothpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_slt_file\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SltGroup, SltDataset, SltAttributes\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mCompound\u001b[39;00m():\n\u001b[1;32m    124\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;124;03m    The core object constituting the API and access to all the methods.\u001b[39;00m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m~/Sloth/Sloth/slothpy/core/_slt_file.py:27\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mslothpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_general_utilities\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _rotate_and_return_components, _return_components, _return_components_diag\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mslothpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_general_utilities\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_io\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _get_dataset_slt_dtype, _group_exists\n\u001b[0;32m---> 27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mslothpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_delayed_methods\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SltStatesEnergiesCm1, SltStatesEnergiesAu, SltZeemanSplitting\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mSltAttributes\u001b[39;00m:\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, hdf5_file, item_path):\n",
      "File \u001b[0;32m~/Sloth/Sloth/slothpy/core/_delayed_methods.py:27\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mslothpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_drivers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _SingleProcessed, _MultiProcessed\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mslothpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_general_utilities\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_constants\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m H_CM_1\n\u001b[0;32m---> 27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mslothpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_magnetism\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_zeeman_lanczos\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _zeeman_splitting_proxy\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m################# __slots__ in every slt class!!\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mSltStatesEnergiesCm1\u001b[39;00m(_SingleProcessed):\n",
      "File \u001b[0;32m~/Sloth/Sloth/slothpy/_magnetism/_zeeman_lanczos.py:42\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mslothpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_general_utilities\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_io\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     39\u001b[0m     _get_soc_magnetic_momenta_and_energies_from_hdf5,\n\u001b[1;32m     40\u001b[0m )\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mslothpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_general_utilities\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_math_expresions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _3d_dot\n\u001b[0;32m---> 42\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mprimme\u001b[39;00m\u001b[38;5;241m,\u001b[39m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msparse\u001b[39;00m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;129m@jit\u001b[39m([\n\u001b[1;32m     45\u001b[0m     types\u001b[38;5;241m.\u001b[39mArray(complex64, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m'\u001b[39m)(\n\u001b[1;32m     46\u001b[0m         types\u001b[38;5;241m.\u001b[39mArray(complex64, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m), \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     65\u001b[0m     magnetic_momenta, states_energies, field, orientation\n\u001b[1;32m     66\u001b[0m ):\n\u001b[1;32m     67\u001b[0m     magnetic_momenta \u001b[38;5;241m=\u001b[39m _3d_dot(magnetic_momenta, \u001b[38;5;241m-\u001b[39mfield \u001b[38;5;241m*\u001b[39m orientation)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'primme'"
     ]
    }
   ],
   "source": [
    "import slothpy as slt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "# Make sure you have access to the libraries on your machine."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f0f7a70",
   "metadata": {},
   "source": [
    "\n",
    "# Creating a Compound Object in SlothPy\n",
    "\n",
    "To start using SlothPy, it's essential to create an instance of the `Compound` class, which is a core element of SlothPy. The `Compound` instance is directly linked to a `.slt` file on your disk and provides access to all the methods serving as a user interface/API. You can create a `Compound` object from the output of quantum chemistry software, work with an existing `.slt` file, or append new data to it. Those operations are handled by the Compound creation methods (see [documentation](https://slothpy.org/creation_methods)). In this tutorial, we'll utilize a `.rassi.h5` file from a MOLCAS calculation, available for download [here](https://drive.google.com/file/d/1obU_bK9sc2hdy3vFXjLxtTUX7CBzl-wf/view) or on the [website](https://slothpy.org/how_to_start) (you can try to use your file if you already have access to one). To create a `Compound` from this file, we use the [`slt.compound_from_molcas()`](https://slothpy.org/creation_methods#slothpy.compound_from_molcas) method. It's important to always refer to the [documentation](https://slothpy.org/reference_manual) for details on the methods we use. In Jupyter Notebooks, a quick way to access method docstring is to press `Shift` + `Tab` in parenthesis after typing the method name. You need to provide appropriate paths and names for the files. (you can click the underscored links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29267b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "NdCo = slt.compound_from_molcas(\".\", \"Nd_tutorial\", \"bas3\", \".\", \"YbCN_DPPMO2_small_bas2\")\n",
    "# Provide paths to the locations of your .rassi.h5 file and where you want to store the resulting .slt file\n",
    "# replacing \".\". You can also adjust the names."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58098321",
   "metadata": {},
   "source": [
    "We named the instance `NdCo`, and now it's directly linked to the new file `Nd_tutorial.slt`. After the creation, you can check what is inside your file using the print() method or directly in Notebook like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "becceb4b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "NdCo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cddbc2b",
   "metadata": {},
   "source": [
    "You should see the list of HDF5 groups (with `bas3` among them) and data sets contained in the file, together with their description attributes. This is the way that SlothPy will save all your future results. Having already .slt file on your disk, you can add to it more ab initio results (just use the path and name of an existing file) or access it at a later point using the [`slt.compound_from_slt() method`](https://slothpy.org/creation_methods#slothpy.compound_from_slt). You can also create many instances and files for different compounds or store them all in one file - the decision is up to you. More advanced use cases in actual workflows are demonstrated in Tutorial 2. (If you are interested in adding a new file format for loading energies, spin, and angular momenta data from your favorite quantum-chemistry package, please get in touch with me directly: mikolaj.zychowicz@uj.edu.pl or create an [issue](https://github.com/MTZ-dev/slothpy/issues).)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a403f2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "NdCo = slt.compound_from_slt(\".\", \"Nd_tutorial\")\n",
    "# If you have created \"Nd_tutorial.slt\" on your disk, only use this line."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17cd087b",
   "metadata": {},
   "source": [
    "## Utilizing SlothPy's  Methods\n",
    "\n",
    "All available methods are accessed through an instance of the Compound class that constitutes the user interface and API documented in the [Reference Manual](https://slothpy.org/reference_manual). Let us start by computing molar powder-averaged magnetisation as a function of temperature and magnetic field strength `M(T,H)` for our Nd-based compound. We must create one-dimensional lists or arrays of temperature and field values at which the magnetization will be computed. It's convenient to use the numpy linspace method here for fields between 0 and 7 T (50 points) and temperatures from 1 to 10 K with 1 K step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36cf472d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fields_mth = np.linspace(0.0001, 7, 10000)\n",
    "temperatures_mth = np.linspace(1, 10, 300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d11c1c64",
   "metadata": {},
   "source": [
    "After that, we should reference the NdCo object. Use `NdCo. + Tab` here in the notebook or autocompletion in our IDE to see the list of all available functions. The method for computing magnetisation as a function of field and temperature is called [`calculate_magnetisation()`](https://slothpy.org/compound#slothpy.Compound.calculate_magnetisation). We need to provide the name of a group from which magnetisation will be calculated along with fields, option for integration grid, temperatures and states cutoff for Zeeman Hamiltonian diagonalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e04dd880",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialization...\n",
      "Calculate Magnetisation started: 2024-01-22 01:00:53\n",
      "Progress: |--------------------------------------------------| 0.00% | Time: 0.0 s |\n",
      "CPU Usage: 3.8% | Memory Usage: 2.7% | Processes: 128 | Threads per Process: 1 Progress: |--------------------------------------------------| 0.00% | Time: 0.2 s |\n",
      "Progress: |--------------------------------------------------| 0.00% | Time: 0.4 s |\n",
      "Progress: |--------------------------------------------------| 0.00% | Time: 0.6 s |\n",
      "Progress: |--------------------------------------------------| 0.00% | Time: 0.8 s |\n",
      "Progress: |--------------------------------------------------| 0.00% | Time: 1.0 s |\n",
      "Progress: |#-------------------------------------------------| 2.64% | Time: 1.2 s |\n",
      "Progress: |#####---------------------------------------------| 10.19% | Time: 1.4 s |\n",
      "Progress: |########------------------------------------------| 17.88% | Time: 1.6 s |\n",
      "Progress: |############--------------------------------------| 25.02% | Time: 1.9 s |\n",
      "Progress: |################----------------------------------| 32.80% | Time: 2.1 s |\n",
      "Progress: |####################------------------------------| 40.61% | Time: 2.3 s |\n",
      "Progress: |########################--------------------------| 48.10% | Time: 2.6 s |\n",
      "Progress: |###########################-----------------------| 55.61% | Time: 2.8 s |\n",
      "Progress: |###############################-------------------| 63.06% | Time: 3.0 s |\n",
      "Progress: |###################################---------------| 70.78% | Time: 3.3 s |\n",
      "Progress: |#######################################-----------| 78.48% | Time: 3.5 s |\n",
      "Progress: |##########################################--------| 85.94% | Time: 3.7 s |\n",
      "Progress: |##############################################----| 93.64% | Time: 4.0 s |\n",
      "Progress: |#################################################-| 99.40% | Time: 4.2 s |\n",
      "Progress: |##################################################| 100.00% | Time: 4.4 s |\n",
      "CPU Usage: 7.6% | Memory Usage: 2.9% | Processes: 128 | Threads per Process: 1 \n",
      "Compleated: 2024-01-22 01:00:57\n",
      "CPU times: user 2.58 s, sys: 11.9 s, total: 14.5 s\n",
      "Wall time: 4.68 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "slt.turn_on_monitor()\n",
    "mth = NdCo.calculate_magnetisation(\"bas3\", fields_mth, 4, temperatures_mth, 14)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d027cb60",
   "metadata": {},
   "source": [
    "Here, we calculate powder-averaged (using Lebedev-Laikov integration grid on the hemisphere) magnetisation for the Nd-based compound in the magnetic field range from 1 Oe to 7 T (50 points) and for ten temperature values from 1 K to 10 K. We include in the Zeeman Hamiltonian only 10 Spin-Orbit states from the ground multiplet $ ^{4}I_{9/2} $ of Nd(III). The calculation should finish immediately due to the very low amount of SO states included.\n",
    "\n",
    "The result is a numpy NdArray (10, 50) with the structure [temperatures, fields] returned from the function call to the mth variable. It is ready for you to process it using Python as you want. Remember to always check the output format of methods in the [Reference Manual](https://slothpy.org/reference_manual) (or using your editor/IDE) - `Returns` section of each function in the documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a6cdfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "mth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d712c7a",
   "metadata": {},
   "source": [
    "# Data Manipulation and Visualisation\n",
    "SlothPy seamlessly interfaces with the broader toolchain and Python scientific ecosystem by returning data in numpy array format. This compatibility allows you to leverage the full range of Python's data manipulation, exporting, and visualization tools in your scripts using your favorite libraries. As an illustrative example, let's plot the data contained in mth variable as a magnetic field function M(H) iterating over different temperatures using matplotlib:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4690886a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for mh in mth:\n",
    "    plt.plot(fields_mth, mh)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af6c8426",
   "metadata": {},
   "source": [
    "If you need to export the data to use it elsewhere we can simply save it to a .csv file on the disk to be accessible for you or your other programs directly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a19aca8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('my_mth_array.csv', mth.T, delimiter=',')\n",
    "# Here we transpose to have the data for each temperature value in columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3429f7e",
   "metadata": {},
   "source": [
    "We can make it even better and create a well-formated data frame using pandas library for the data exporting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9559a2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "fields_oe = fields_mth * 10000\n",
    "magnetisation_df = pd.DataFrame({'Fields (Oe)': fields_oe})\n",
    "\n",
    "for i, mh in enumerate(mth):\n",
    "    magnetisation_df[f\"{temperatures_mth[i]} K\"] = mh\n",
    "\n",
    "magnetisation_df.to_csv(os.path.join(\".\", \"magnetisation.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c4b5868",
   "metadata": {},
   "source": [
    "As you can see, the possibilities are endless."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab9bbe00",
   "metadata": {},
   "source": [
    "Nevertheless, SlothPy offers you its own organized data storage inside the core .slt files along with a series of built-in methods to visualize it and proceed with multi-step complex computations. To demonstrate it, we will now run the above calculation once again, but this time we will use a better, denser grid and include more SO-states. It will take a little more time. Additionally, we will save the results to our Nd_tutorial.slt file using `slt` keyword. (confront the [documentation](https://slothpy.org/compound#slothpy.Compound.calculate_magnetisation) for the comprehensive description of all the options). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18fd1a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "mth = NdCo.calculate_magnetisation(\"bas3\", fields_mth, 6, temperatures_mth, 14, slt=\"bas32\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a7dd207",
   "metadata": {},
   "source": [
    "If you invoke the representation of the Nd_tutorial.slt file once again, you can see that a new group \"bas3_magnetisation\" was created which contains datasets for magnetisation (bas3_mth), magnetic fields (bas3_fields), and temperatures (bas3_temperatures). (all with description attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b2424f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "NdCo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a33b0828",
   "metadata": {},
   "source": [
    "SlothPy provides an array-like interface for reading and writing data from and to .slt files. To access a particular dataset and read it in as a numpy array, you need to provide the name of a group followed by the dataset's name. As an example, let us read the magnetisation to another variable mth_custom_read together with field values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1abdd048",
   "metadata": {},
   "outputs": [],
   "source": [
    "mth_read = NdCo[\"bas3_magnetisation\", \"bas3_mth\"]\n",
    "field_values_read = NdCo[\"bas3_magnetisation\", \"bas3_fields\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c6b67fe",
   "metadata": {},
   "source": [
    "Here, we provide a <u>full</u> group and dataset name (with suffixes) to access the data! Now, once again, we can do whatever we want with the arrays. Let us confirm that they indeed represent the same magnetisation as before by plotting them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688ac510",
   "metadata": {},
   "outputs": [],
   "source": [
    "for mh in mth_read:\n",
    "    plt.plot(field_values_read, mh)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a127429",
   "metadata": {},
   "source": [
    "Since we have our data saved in the .slt file, we can plot it using the build-in function (available for various methods and having plenty of customizable parameters - see all the methods starting with \"plot\" in the [documentation](https://slothpy.org/reference_manual))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "25833511",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Figure saved to /home/mikolaj/Downloads/telomelaza.png with DPI=600\n"
     ]
    }
   ],
   "source": [
    "NdCo.plot_magnetisation(\"bas32\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34717331",
   "metadata": {},
   "source": [
    "As you noticed, when using the built-in functions, you do not need to (actually, you can't) provide a name of the group with a suffix, like \"_magnetisation\"; just use the name you gave for the `slt` parameter of the method and the program will handle the rest for you.\n",
    "\n",
    "If you want to integrate the .slt file in your workflow (e.g., adding experimental data), you can even create your custom groups with datasets (in the form of numpy NdArrays) in the file and use them in your programs and scripts simply by using a `Compound` class instance connected to the file - NdCo[...]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "553e3b4f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "one_to_ten = np.linspace(1, 10, 10)\n",
    "NdCo[\"my_custom_group\", \"one_to_ten_dataset\", \"My description of the dataset\",\n",
    "     \"My description of the whole group\"] = one_to_ten\n",
    "NdCo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b365bd",
   "metadata": {},
   "source": [
    "The last two strings, setting a description of the dataset and group, are optional and ordered in such a way as to make it possible to add datasets to the same group later without repeating its description. All the values you can store must be in an ArrayLike form (can be converted to the numpy NdArray). As an example, we add to our new group a new dataset with a description, a new dataset without a description, and a stand-alone dataset without any group. (the data must be at least one-dimensional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f144e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "NdCo[\"my_custom_group\", \"dataset_with_description\", \"Identity matrix\"] = [[1,0,0],[0,1,0],[0,0,1]]\n",
    "NdCo[\"my_custom_group\", \"123_dataset\"] = [1,2,3]\n",
    "NdCo[\"my_dataset_without_a_group\"] = [1]\n",
    "NdCo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c9eff25",
   "metadata": {},
   "source": [
    "Suppose you now re-run the previous calculation. In that case, you should see a SlothPyError due to the already existing name of the group (SlothPy prevents you from accidentally overwriting the data). The library has extensive custom error handling, eliminating tedious, long tracebacks and trying to inform users directly about all sorts of potential problems, hopefully making the user experience less painful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f700e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "mth = NdCo.calculate_magnetisation(\"bas3\", fields_mth, 6, temperatures_mth, 32, slt=\"bas3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5968c7f",
   "metadata": {},
   "source": [
    "Finally, we can use [delete_group_dataset()](https://slothpy.org/compound#slothpy.Compound.delete_group_dataset) to manually remove datases/groups from the .slt file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "887b940f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "NdCo.delete_group_dataset(\"my_dataset_without_a_group\")\n",
    "NdCo.delete_group_dataset(\"my_custom_group\", \"123_dataset\") # Only the 123_dataset is removed\n",
    "NdCo.delete_group_dataset(\"bas3_magnetisation\") # The whole group is removed\n",
    "NdCo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "016a1201",
   "metadata": {},
   "source": [
    "As a final remark, remember that the .slt files are, in fact, HDF5 files in disguise. That means you can obtain all the above functionalities (and much more) directly using, for example, the h5py Python wrapper in your scripts for .slt file reading and modifications, further incorporating them into your data pipelines."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd9d8c0",
   "metadata": {},
   "source": [
    "# Optimizing Computational Performance with SlothPy:\n",
    "# Parallel Processing and Autotuning\n",
    "As you should have already noticed (when reading the docstring of [calculate_magnetisation()](https://slothpy.org/compound#slothpy.Compound.calculate_magnetisation) method), SlopthPy provides you full control over the number of CPUs you want to assign to your calculation and the threads to be used for linear algebra libraries. Computationally demanding methods are parallelized using a certain amount of separate Python processes - the number of processes that will be used is (number of CPUs) // (number of threads). Additionally, in the \"Note\" section of each method's documentation, the user is informed over what quantity the job will be parallelized. In the case of [calculate_magnetisation()](https://slothpy.org/compound#slothpy.Compound.calculate_magnetisation)  method, the work is distributed over different field values (here 50). So, when using, for example, 10 parallel processes, each will compute the magnetisation for 5 values of the magnetic field. As default, SlothPy uses all available logical cores with 1 thread assigned for the linear algebra libraries. For jobs with a very high number of points to be parallelized over, you should benefit from a greater number of processes. On the other hand, with increasing matrix sizes, it is beneficial to use more threads for operations such as diagonalization, dot products, etc. It is not a trivial task to choose optimal settings for very demanding calculations, and that is why we provide, within SlothPy, the autotune module to do it for you. It tests all possible meaningful setups and gives you time estimates for each of them. It takes some time to do this (because it actually truly does a part of the calculations to benchmark them), so it is advised to use it for jobs that will take hours. To demonstrate it with relatively small matrices available in our file (they are at most 364 x 364 with states_cutoff set to 0 - that is how many SO states there are), we will run two examples using all available CPUs on your machine (if you want to leave some for other tasks you should change number_cpu = 0 to your desired number):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f74f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "fields_process = np.linspace(0.0001, 7, 60)\n",
    "fields_threads = np.linspace(0.0001, 7, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4708d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "mth = NdCo.calculate_magnetisation(\"bas3\", fields_process, 6, temperatures_mth, 14, number_cpu = 16, autotune=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c97efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "mth = NdCo.calculate_magnetisation(\"bas3\", fields_threads, 6, temperatures_mth, 14, number_cpu = 16, autotune=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0bf56cf",
   "metadata": {},
   "source": [
    "In the first case, the autotune module should choose (but it depends on your hardware and CPU number) more processes and fewer threads than in the second one, where we parallelize only over 3 field points. Time estimates include only pure calculation steps, and in our tests for a variety of different methods, they should give results within 20-30% maximal error of overall execution time. After the autotuning, you can run the calculation with the chosen setting manually to see how much time it will take compared to our estimate. Can you choose better settings by yourself?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "958a39d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_cpu = 16 #fill here the number you were autotuning for\n",
    "num_of_threads = 2 #fill here the number of threads chosen by the autotune module (for fields_process and _threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fbb4fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "mth = NdCo.calculate_magnetisation(\"bas3\", fields_process, 6, temperatures_mth, 14, num_of_cpu, num_of_threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1ebdf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "mth = NdCo.calculate_magnetisation(\"bas3\", fields_threads, 6, temperatures_mth, 14, num_of_cpu, num_of_threads)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "399da4a1",
   "metadata": {},
   "source": [
    "The necessity of the autotune module will become visible for matrices with a number of states over 500-1000 or even 2000+ when calculations with certain settings (how many field values and grids) can take many hours or even days. It also all depends on your hardware e.g. how many possibilities is there to check. For me writing this tutorial now I am testing it on 128 logical cores (64 physical) CPU, so there are many possibilities to choose a number of threads and processes - therefore it is harder and also more time-consuming for the module, but still better than trying manually all the possibilities."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93855405",
   "metadata": {},
   "source": [
    "In the following part of the tutorial, we will give a glimpse into more methods presenting their use for our Nd-based compound. Make sure to check the documentation of each presented method - it always contains a comprehensive description of all the used parameters. We begin by calculating magnetic susceptibility - in the form of a product with temperature - (the derivative of magnetisation with respect to the magnetic field) in 1000, 2000, 3000, and 5000 Oe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f3ee15",
   "metadata": {},
   "outputs": [],
   "source": [
    "temperatures = np.linspace(1, 300, 300)\n",
    "fields = [0.1, 0.2, 0.3, 0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "549acc68",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "chitht = NdCo.calculate_susceptibility(\"bas3\", temperatures, fields, number_of_points=2, delta_h=0.0001,\n",
    "                               states_cutoff=14, number_cpu=0, number_threads=1, T=True, slt=\"your_name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "707e7967",
   "metadata": {},
   "outputs": [],
   "source": [
    "NdCo.plot_susceptibility(\"your_name\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba38dc36",
   "metadata": {},
   "source": [
    "You can calculate the Helmholtz free energy or internal energy in the applied magnetic field (here instead of averaging we calculate with the field applied in the \"z\" direction):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d2ad93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "temperatures = np.linspace(1, 300, 300)\n",
    "fields = np.linspace(0.0001, 10, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "769cc6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "eth = NdCo.calculate_energy(\"bas3\", fields, [[0., 0., 1., 1.]], temperatures, \"helmholtz\", 14, number_cpu=0, \n",
    "                                  number_threads=1, slt=\"your_name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34522549",
   "metadata": {},
   "outputs": [],
   "source": [
    "NdCo.plot_energy(\"your_name\", \"helmholtz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b639a5",
   "metadata": {},
   "source": [
    "You can calculate the Zeeman splitting of the ground $ ^{4}I_{9/2} $ multiplet for various directions (here x, y, z) or take powder-average:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774e6746",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "zeeman = NdCo.calculate_zeeman_splitting(\"bas3\", 8, fields, [[1,0,0],[0,1,0],[0,0,1]], states_cutoff=14,\n",
    "                                number_cpu=0, number_threads=1, average=False, slt=\"your_namee\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "719036f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "NdCo.plot_zeeman(\"your_namee\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be59f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "g, axes = NdCo.calculate_g_tensor_and_axes_doublet(\"bas3\", [0], slt=\"axes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58804fc2",
   "metadata": {},
   "source": [
    "SlothPy allows you to calculate directional data of the above quantities in the form of 3D plots over spherical angles. This type of calculation is pretty demanding and heavy on memory usage. See the Note sections for the following methods to see examples of memory estimation that is needed to handle big resulting and intermediate arrays!!! (example: for a calculation with 100 field values 1-10 T, 300 temperatures 1-300 K,\n",
    "and spherical_grid = 60, the resulting array will take 3 * 100 * 300 * 2 * 60 * 60 * 8 bytes = 5.184 GB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4333c002",
   "metadata": {},
   "outputs": [],
   "source": [
    "g, axes = NdCo.calculate_g_tensor_and_axes_doublet(\"bas3\", [0])\n",
    "axes = axes[0].T\n",
    "axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130939f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "r = NdCo.calculate_energy_3d(\"bas3\", fields, \"mesh\", 35, temperatures, \"helmholtz\", 14, slt=\"your_name\", number_cpu=16, rotation=axes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a6f55d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "r = NdCo.calculate_magnetisation_3d(\"bas3\", fields, \"mesh\", 35, temperatures, 14, slt=\"your_name\", number_cpu=16, rotation=axes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f228ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "r = NdCo.calculate_susceptibility_3d(\"bas3\", temperatures, fields, \"mesh\", 35, 2, states_cutoff=14,  number_cpu=16, slt=\"your_name\", rotation=axes)\n",
    "# Carefull! This is the most demanding calculation it has to perform (2*number_of_points+1) times the \n",
    "# magnetisation calculation for numerical differentiation using finite difference method with the custom stencil."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6afbb844",
   "metadata": {},
   "source": [
    "At this point, you may need to adjust (lower or raise) states_cutoff-s, density of spherical grid, or number of field values depending on your hardware (CPU and memory) capability. Also, the autotune module should always choose 1 thread due to the large number of the point we parallelize over (number of fields) * 2 * spherical_grid**2, since your matrices are small and can have at most 364 x 364 size it cannot prioritize multithreading for them.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f71f41d",
   "metadata": {},
   "source": [
    "After you succeed we can plot the results for particular temperatures and field values with the plot_3d method which supports energy, magnetisation, and susceptibility plotting (see the datatype keyword):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4270d42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "NdCo.plot_3d(\"your_name\", \"helmholtz_energy\", 10, 30) \n",
    "# Options: \"helmholtz_energy\", \"internal_energy\", \"magnetisation\", \"chi\", \"chit\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9196f48f",
   "metadata": {},
   "source": [
    "Anyway, probably the best method to examine this type of data is to scan it using an interactive 3D plot where you can change fields and temperatures using sliders and see changes in real-time!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085e6f67",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "NdCo.interactive_plot_3d(\"your_name\", \"chit\", add_g_tensor_axes=True, axes_group=\"axes\", axes_scale_factor=1.5,\n",
    "                        doublet_number=0, rotation=axes)\n",
    "# Options: \"helmholtz_energy\", \"internal_energy\", \"magnetisation\", \"chi\", \"chit\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f63a859e",
   "metadata": {},
   "source": [
    "After you manually find all the instersting \"phase\" transitions you can even prepare .gif animations varying temperature or field strenght while keepeing the other constant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87f9595",
   "metadata": {},
   "outputs": [],
   "source": [
    "NdCo.animate_3d(\"your_name\", \"helmholtz_energy\", \"temperature\", \"animation\", i_start=0, i_end=30, i_constant=2,\n",
    "               fps=6, dpi=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f3b8427",
   "metadata": {},
   "source": [
    "The animation should be saved to your current directory."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace815ac",
   "metadata": {},
   "source": [
    "We will end this basic tutorial just by mentioning other methods. More advanced combinations resulting in e.g. studies on relaxation dynamics for molecular magnets will be addressed in more specialized tutorials."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d1bee3",
   "metadata": {},
   "source": [
    "In order to calculate pseudo-g-tensors for doublet states within the ground $ ^{4}I_{9/2} $ multiplet (10 states - 5 doublets) you can run the:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728dbfbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "g_tensors, magnetic_axes = NdCo.calculate_g_tensor_and_axes_doublet(\"bas3\", [0,1,2,3,4]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a64be17",
   "metadata": {},
   "outputs": [],
   "source": [
    "g_tensors, magnetic_axes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e8de784",
   "metadata": {},
   "source": [
    "The first entry of the tuple contains g-tensor components x, y, and z for the doublets and magnetic_axes are rotation matrices from the initial coordinate system to the main magnetic axes of each doublet (Coordinates of the main axes X, Y, and Z in the initial x, y, z frame are columns of such matrices). We can use those matrices to rotate angular momenta in almost all the following methods to express the quantities in the reference frame of the chosen doublet's magnetic axes. Note, that you need to use the inverse rotation (transpose of an orthogonal matrix) to express everything in the new reference frame! (see also Exporting Module for an easy way to add the main magnetic axes to your .mol2/.xyz files with molecular coordinates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db98b552",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "your_rotation = magnetic_axes[0].T # Inverse rotation for the ground doublet\n",
    "your_rotation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97525261",
   "metadata": {},
   "source": [
    "As an example, we calculate the susceptibility (Van-Vleck) tensor using true numerical differentiation in the reference frame of the ground doublet state:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfdbd46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "temperatures = linspace(1, 300, 300)\n",
    "fields = [0.1, 0.2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b08736e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "NdCo.calculate_chit_tensorht(\"bas3\", temperatures, fields, number_of_points=3, delta_h=0.0001, states_cutoff=364,\n",
    "                             number_cpu=0, number_threads=1, rotation=your_rotation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e17552c4",
   "metadata": {},
   "source": [
    "Now we will do a little demonstration considering our 10-state ground manifold. Firstly, let us take a look at SOC energies of the states:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72357610",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "NdCo.soc_energies_cm_1(\"bas3\", 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1520827",
   "metadata": {},
   "source": [
    "They come in doublets as expected for the Krammers ion. We can then obtain Crystal-Fields-Parameters for S = 9/2 pseudo-spin (in the form of J - total angular momneta) for the SOC matrix taking as \"z\" quantization axis the main magnetic axis of a ground doublet (use your_rotation). Note that the order of CFPs cannot exceed 2S here and because SOC Hamiltonian (without magnetic fields) is time even operator we only need even orders. We will use real parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e50d0170",
   "metadata": {},
   "outputs": [],
   "source": [
    "NdCo.soc_crystal_field_parameters(\"bas3\", 0, 9, order=9, pseudo_kind = \"magnetic\", \n",
    "                                  even_order=True, rotation=your_rotation, slt=\"your_name\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ad03a1",
   "metadata": {},
   "source": [
    "For the comparison let us get the initial SOC matrix in the same pseudo-spin Jz basis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab7a32a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "soc_matrix = NdCo.soc_zeem_in_z_angular_magnetic_momentum_basis(\"bas3\", 0, 9, \"soc\", \"magnetic\",\n",
    "                                                                rotation=your_rotation)\n",
    "soc_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce1751b9",
   "metadata": {},
   "source": [
    "Verify it by computing its eigenvalues which should be the same as SOC energies from before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a8d6cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.linalg import eigvalsh\n",
    "energies = eigvalsh(soc_matrix) * 219474.6 # Convert it from Hartree to cm-1\n",
    "energies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f86d0a",
   "metadata": {},
   "source": [
    "We can rebuild the whole matrix from the saved CFP (ITO) parameters and verify that it is the same as soc_matrix (giving the same eigenvalues):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de595ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "soc_matrix_from_cfp = NdCo.matrix_from_ito(\"your_name_soc_ito_decomposition\", False)\n",
    "\n",
    "energies = eigvalsh(soc_matrix_from_cfp) * 219474.6 # Convert it from Hartree to cm-1\n",
    "energies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e9b0b2a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "soc_matrix - soc_matrix_from_cfp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fd2f98b",
   "metadata": {},
   "source": [
    "If you need numerical precision for the matrix recreation, you should use odd orders of ITOs (Irreducible Tensor Operators) as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0004b24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "NdCo.soc_crystal_field_parameters(\"bas3\", 0, 9, order=9, pseudo_kind = \"magnetic\", \n",
    "                                  even_order=False, rotation=your_rotation, slt=\"your_name_odd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf7cc32",
   "metadata": {},
   "outputs": [],
   "source": [
    "soc_matrix_from_cfp_odd = NdCo.matrix_from_ito(\"your_name_odd_soc_ito_decomposition\", False)\n",
    "\n",
    "energies = eigvalsh(soc_matrix_from_cfp) * 219474.6 # Convert it from Hartree to cm-1\n",
    "energies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "656d7d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "soc_matrix - soc_matrix_from_cfp_odd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a27b4c4d",
   "metadata": {},
   "source": [
    "Using all orders is necessary e.g. when dealing with Zeeman Hamiltonians containing interaction with magnetic field on top of the energy of SOC states. We can follow the seam procedure for a full Zeeman matrix originating from interaction with a magnetic field in the \"y\" direction (2 T):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7419430",
   "metadata": {},
   "outputs": [],
   "source": [
    "NdCo.zeeman_matrix_ito_decpomosition(\"bas3\", 0, 9, 2, [0., 1., 0.], order=9, pseudo_kind = \"magnetic\", \n",
    "                                     rotation=your_rotation, slt=\"your_name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48895bb7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "zeeman_matrix = NdCo.soc_zeem_in_z_angular_magnetic_momentum_basis(\"bas3\", 0, 9, \"zeeman\", \"magnetic\", field=2.,\n",
    "                                                                   orientation= [0., 1., 0.],\n",
    "                                                                   rotation=your_rotation)\n",
    "zeeman_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1018beb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "zeeman_matrix_from_cfp = NdCo.matrix_from_ito(\"your_name_zeeman_ito_decomposition\", False)\n",
    "\n",
    "energies = eigvalsh(zeeman_matrix_from_cfp) * 219474.6 # Convert it from Hartree to cm-1\n",
    "energies # Zeeman splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d082a5ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "energies = eigvalsh(zeeman_matrix) * 219474.6 # Convert it from Hartree to cm-1\n",
    "energies # Zeeman splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b2ca6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "zeeman_matrix - zeeman_matrix_from_cfp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6782f89",
   "metadata": {},
   "source": [
    "Feel free to experiment with two available pseudo-spin bases (total angular or magnetic)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b493e9",
   "metadata": {},
   "source": [
    "We will end this short introduction to SlothPy software by showing how to obtain a % decomposition in the pseudo-spin basis of a SOC/Zeeman matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb50446b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "NdCo.matrix_decomposition_in_z_pseudo_spin_basis(\"bas3\", \"soc\", \"magnetic\", 0, 9, rotation=your_rotation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4116b87a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "NdCo.matrix_decomposition_in_z_pseudo_spin_basis(\"bas3\", \"zeeman\", \"magnetic\", 0, 9, rotation=your_rotation,\n",
    "                                                orientation=[0., 1., 0.], field=2.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c8ea8f",
   "metadata": {},
   "source": [
    "Here, the resulting matrix contains % weights of pseudo-spin states (columns - from -S to S) in each state from the list (rows - here 10 states from 0 to 9) where pseudo-spin number S = number_of_states / 2 - 1/2 = 10/2 - 1/2 = 9/2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53110b0c",
   "metadata": {},
   "source": [
    "To explore more methods check the Reference Manual and more specialized, upcoming tutorials."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beeb1295",
   "metadata": {},
   "source": [
    "MTZ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
